{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos estudar 5 tipos de agentes em IA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agente de Reflexos Simples\n",
    "---\n",
    "Tipo de agente mais elementar. Escolhe a ação a tomar tendo apenas em conta as perceções atuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [...] # conjunto de regras condição-ação\n",
    "def simple_reflex_agent(perception):\n",
    "\n",
    "    state = interpret_input(perception)\n",
    "    rule = pair_rule(state, rules)\n",
    "    action = rule_action[rule]\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agente de Reflexos baseados em Modelos (ou Agente de Reflexos Simples com Estado Interno)\n",
    "\n",
    "---\n",
    "\n",
    "Em ambientes parcialmente observáveis, o agente vair, por norma, precisar de manter um estado interno (histórico de perceções) onde vai mapeando as partes do mundo que já viu (e que pode ou não estar a ver agora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [...] # conjunto de regras condição-ação\n",
    "state = [...] # descrição do estado do mundo\n",
    "action = [...] # a ação mais recente\n",
    "def model_based_reflex_agent(perception):\n",
    "    state = update_state(state, action, perception)\n",
    "    rule = pair_rule(status, rules)\n",
    "    action = rule_action[rule]\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agentes baseados em Objetivos\n",
    "---\n",
    "Agentes aos quais podemos arbitrariamente dar um objetivo, e utilizando uma lógica semelhante à dos agentes baseados em modelos (guardando estado interno, etc.) conseguimos obter ações que nos colocam mais próximos de atingir o objetivo.\n",
    "\n",
    "Este tipo de agente distingue-se dos últimos dois porque deixa de ser baseado em reflexos (não há um conjunto de condições-ação definido inicialmente que possamos usar sempre, já que teria de ser adaptado consoate o objetivo). As ações têm de ser definidas de forma dinâmica, de acordo com as considerações do agente quanto ao futuro (\"o que é que acontece se fizer isto?\", entre outros)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agentes baseados em Utilidade\n",
    "---\n",
    "Semelhante ao de cima, mas têm uma função de utilidade, uma \"medida\" que permite diferenciar ações a tomar numa mesma situação (que levariam ao mesmo objetivo) consoante um conjunto de preferências estabelecidas inicialmente.\n",
    "\n",
    "Por exemplo, num robô taxista podemos definir preferências como tempo e lucro como parâmetros a ter em conta na decisão da ação a tomar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agentes com Aprendizagem (learning agents)\n",
    "---\n",
    "Correspondem à ideia inicial de máquina inteligente caraterizada por Turing, onde o agente atua num mundo que inicialmente desconhece. A ideia possui 4 elementos-chave:\n",
    "\n",
    "- Elemento de crítica: corresponde a um padrão de performance que avalia o que os sensores percecionam e dá o feedback correspondente ao elemento de aprendizagem.\n",
    "- Elemento de aprendizagem: tem como propósito tornar o agente mais eficiente ao longo do tempo, pega no feedback dado pela critíca e faz as alterações necessárias de acordo com o mesmo.\n",
    "- Elemento de performance: seleciona a ação a tomar pelo agente (dentro do leque das ações que pode tomar agora) consoante o que espera surtir melhores resultados ou consoante o que o gerador de problemas lhe indicou.\n",
    "- Gerador de problemas: \"copiloto\" que sugere ações a tomar, que podem trazer informação útil (a partir da qual podemos vir a perceber melhor/ter mais certezas sobre as ações ótimas do agente)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
